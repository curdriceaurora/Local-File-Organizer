---
name: remove-synthetic-hash-insertion
title: Remove synthetic hash insertion for unique files in duplicate detector
status: open
created: 2026-01-21T09:18:28Z
updated: 2026-01-21T09:22:45Z
size: M
hours: 4
parallel: false
dependencies: []
---

# Issue #76: Remove synthetic hash insertion

## Description

The duplicate detector inserts synthetic hash values for unique files, which creates confusing data and may cause false positives.

## Current Problem

- Synthetic hashes pollute the hash index
- Confusing when debugging (real vs synthetic hashes)
- May cause issues if synthetic hashes are treated as real
- Wastes memory storing unnecessary data
- Unclear purpose: Why track unique files in duplicate index?

## Analysis Required

Before fixing, need to understand:
1. Why are unique files added to hash_index?
2. Is this data used elsewhere in the codebase?
3. Can we simply skip unique files instead?

## Proposed Solution

**Option 1**: Remove synthetic insertion (Recommended)
**Option 2**: Use explicit tracking if needed

## Acceptance Criteria

- [ ] Code analysis completed to understand usage
- [ ] Solution chosen based on requirements
- [ ] Synthetic hash insertion removed or replaced
- [ ] Hash index only contains real duplicates
- [ ] All duplicate detection tests pass
- [ ] Memory usage validated (should decrease)

## Technical Details

**File**: `src/file_organizer/services/deduplication/detector.py` (lines 218-225)
**Priority**: Medium

## References

- CodeRabbit PR #67 review comment
