---
name: perceptual-hashing-similar-images
title: Implement perceptual hashing for similar images
status: open
created: 2026-01-21T05:53:16Z
updated: 2026-01-26T00:52:32Z
size: L
hours: 24
parallel: true
dependencies: []
github: https://github.com/curdriceaurora/Local-File-Organizer/issues/216
---

# Task 002: Implement perceptual hashing for similar images

## Description

Implement perceptual hashing (pHash) for detecting visually similar images using the imagededup library. This system should identify near-duplicate images that may have different resolutions, compression levels, or minor edits. Include a side-by-side comparison UI for user review and implement logic to automatically keep the best quality version based on resolution and file size.

## Acceptance Criteria

- [ ] Integrate imagededup library for perceptual hashing
- [ ] Support for common image formats (JPEG, PNG, GIF, BMP, TIFF, WebP)
- [ ] Visual similarity detection with configurable threshold
- [ ] Side-by-side comparison interface showing image previews
- [ ] Automatic quality detection (resolution, file size, compression)
- [ ] "Keep best quality" logic with override options
- [ ] Batch processing for large image collections
- [ ] Progress indicators with estimated time remaining
- [ ] Report generation with statistics and space savings
- [ ] Integration with existing file organization system
- [ ] Command-line and programmatic API interfaces

## Technical Details

### Implementation Approach

1. **Image Processing Module**
   - Create `ImageDeduplicator` class in `file_organizer/services/deduplication/image_dedup.py`
   - Use imagededup library for pHash computation
   - Support multiple hashing methods: pHash, dHash, aHash
   - Handle corrupt/unreadable images gracefully

2. **Similarity Detection**
   - Implement Hamming distance calculation for hash comparison
   - Configurable similarity threshold (0-64 for 64-bit hashes)
   - Group similar images into clusters
   - Store similarity scores for user review

3. **Quality Assessment**
   - Implement `ImageQualityAnalyzer` class
   - Metrics: resolution (width × height), file size, format
   - Calculate quality score combining multiple factors
   - Detect if image is edited/cropped version

4. **Comparison UI**
   - Terminal-based image preview using ASCII art or external viewer
   - Display metadata: dimensions, size, format, modification date
   - Interactive selection: keep/delete/skip for each duplicate
   - Batch operations: keep all best quality, manual review

### File Structure
```
file_organizer/services/deduplication/
├── __init__.py
├── image_dedup.py      # ImageDeduplicator class
├── quality.py          # ImageQualityAnalyzer class
├── viewer.py           # ComparisonViewer for UI
└── image_utils.py      # Helper functions for image operations
```

### Key Classes

```python
class ImageDeduplicator:
    def __init__(self, hash_method: str = "phash", threshold: int = 10)
    def find_duplicates(self, directory: Path) -> Dict[str, List[Path]]
    def compute_similarity(self, img1: Path, img2: Path) -> float

class ImageQualityAnalyzer:
    def assess_quality(self, image_path: Path) -> float
    def compare_quality(self, img1: Path, img2: Path) -> int
    def get_best_quality(self, images: List[Path]) -> Path

class ComparisonViewer:
    def show_comparison(self, images: List[Path]) -> Path
    def batch_review(self, duplicate_groups: Dict) -> Dict[Path, str]
```

### Dependencies

- `imagededup`: Core perceptual hashing library
- `Pillow (PIL)`: Image loading and processing
- `numpy`: Numerical operations for hash comparison
- Optional: `termplotlib` or `imgcat` for terminal image preview

## Effort Estimate

- **Size**: Large (L)
- **Estimated Hours**: 24 hours
- **Breakdown**:
  - imagededup integration and hash computation: 6 hours
  - Similarity detection and grouping: 4 hours
  - Quality assessment logic: 4 hours
  - Comparison UI implementation: 6 hours
  - Testing and edge cases: 3 hours
  - Documentation and examples: 1 hour

## Definition of Done

- [ ] All acceptance criteria met
- [ ] imagededup library successfully integrated
- [ ] Unit tests for all core functions with >85% coverage
- [ ] Integration tests with diverse image datasets
- [ ] Performance benchmarks for 1,000+ image collections
- [ ] User documentation with screenshots/examples
- [ ] CLI help text and usage examples
- [ ] Handles edge cases: corrupt images, unsupported formats, permission errors
- [ ] Code reviewed and approved
- [ ] No performance degradation in existing features

## Test Scenarios

1. **Exact duplicates with different names**: Should detect with 100% similarity
2. **Resized images**: Should detect as similar based on threshold
3. **JPEG compression variations**: Should detect as similar
4. **Cropped images**: May or may not detect depending on crop extent
5. **Color-adjusted images**: Should detect if structural similarity remains
6. **Mixed formats (PNG/JPEG)**: Should compare correctly across formats
7. **Large image collections (10,000+ files)**: Performance and memory usage
8. **Corrupt/unreadable files**: Should skip gracefully without crashing
