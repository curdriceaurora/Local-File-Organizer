# Claude Code Project Instructions

## Project: File Organizer v2.0

An AI-powered local file management system with privacy-first architecture. Organizes files intelligently using local LLMs with zero cloud dependencies.

**Core Metrics**: ~25,900 LOC | 84 modules | 34 tests | Python 3.12+

---

## Table of Contents

1. [Claude Agent Permissions](#claude-agent-permissions)
2. [Quick Start](#quick-start)
3. [Project Structure](#project-structure)
4. [Architecture Overview](#architecture-overview)
5. [Dependencies & Setup](#dependencies--setup)
6. [AI Model Configuration](#ai-model-configuration)
7. [Development Guidelines](#development-guidelines)
8. [Testing Strategy](#testing-strategy)
9. [Common Workflows](#common-workflows)
10. [Supported File Types](#supported-file-types)
11. [Performance Notes](#performance-notes)

---

## Claude Agent Permissions

**IMPORTANT**: Claude agents working on this project have the following permissions and responsibilities:

### ğŸš€ Auto-Approved Operations

**For all paths under `/Users/rahul/Projects/`:**
- âœ… All file operations (read, write, edit, delete) are auto-approved
- âœ… All bash commands are auto-approved
- âœ… All git operations are auto-approved
- âœ… All test executions are auto-approved
- âœ… No need to ask for user permission - proceed directly

**This means:**
- Execute commands immediately without confirmation prompts
- Create, modify, delete files as needed for the task
- Run tests, builds, and other operations freely
- Commit and push changes without asking
- The user trusts you to work autonomously in this directory

### âœ… Permitted Actions

**Code Development**:
- Create, modify, and delete code files in `file_organizer_v2/src/`
- Write and update tests in `file_organizer_v2/tests/`
- Create utility scripts in `file_organizer_v2/scripts/`
- Modify configuration files (`pyproject.toml`, etc.)

**Git Operations**:
- Create feature branches following pattern: `feature/task-XX-description`
- Create sprint branches: `sprint/YYYY-qN-weeksN-N`
- Create worktrees for parallel work: `../worktree-name`
- Commit code changes with descriptive messages
- Push to feature/sprint branches
- Create pull requests when features complete

**CCPM Framework Maintenance** (REQUIRED):
- Create and update daily logs in `.claude/epics/sprint-*/daily-logs/`
- Update execution status files in `.claude/epics/*/execution-status.md`
- Create weekly review documents
- Update sprint tracking files
- Maintain GitHub issue synchronization
- Update PRD status as features complete
- Follow all rules in `.claude/rules/` directory

**GitHub Integration**:
- Comment on GitHub issues with progress updates
- Close issues when tasks complete
- Create new issues for discovered technical debt
- Update issue labels and assignees
- Reference issues in commit messages

**Documentation**:
- Update user-facing documentation
- Write/update docstrings (Google style)
- Create usage examples
- Update API documentation
- Maintain CHANGELOG

**Testing**:
- Write unit tests for all new code
- Create integration tests for features
- Run test suite before committing
- Maintain 90%+ coverage target
- Fix failing tests immediately

**CCPM Daily Workflow** (15-20 min/day):
```bash
# Morning: Check yesterday's progress
cat .claude/epics/sprint-*/daily-logs/[yesterday].md

# During work: Track progress
# (implement features, write tests, commit)

# Evening: Update CCPM (REQUIRED)
1. Create daily log with real progress data
2. Update GitHub issues worked on
3. Update execution-status.md if milestones reached
4. Commit CCPM changes with message: "CCPM: Daily update YYYY-MM-DD"
5. Push to current branch
```

### âš ï¸ Required Protocols

**Before GitHub Write Operations** (CRITICAL):
```bash
# ALWAYS check remote origin before creating/editing issues or PRs
remote_url=$(git remote get-url origin 2>/dev/null || echo "")
if [[ "$remote_url" == *"automazeio/ccpm"* ]]; then
  echo "âŒ ERROR: Cannot modify CCPM template repository!"
  exit 1
fi
```

**DateTime Standards** (ALWAYS):
```bash
# Get REAL current datetime - never use placeholders
CURRENT_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

# Use in frontmatter
---
updated: 2026-01-23T14:30:45Z  # Real datetime, not placeholder
---
```

**Path Standards** (ALWAYS):
```markdown
# Use relative paths - NEVER absolute paths with usernames
âœ… src/file_organizer/models/audio_model.py
âœ… ../phase3-audio/src/file_organizer/
âŒ /Users/username/Projects/file_organizer_v2/src/...
```

**Frontmatter Standards** (ALWAYS):
```yaml
---
name: descriptive-name
created: 2026-01-23T09:00:00Z  # Set once, never change
updated: 2026-01-23T14:30:00Z  # Update on every modification
status: backlog|in-progress|completed
---
```

### ğŸš« Prohibited Actions

**Code**:
- âŒ Modifying `.git/` directory directly
- âŒ Force pushing (`git push --force`) to main/protected branches
- âŒ Committing secrets, API keys, or credentials
- âŒ Modifying user data or configuration files
- âŒ Running destructive operations without confirmation

**Git**:
- âŒ Pushing directly to `main` branch (use PRs)
- âŒ Deleting remote branches without confirmation
- âŒ Amending commits that are already pushed
- âŒ Rebasing shared branches
- âŒ Creating merge commits in feature branches

**GitHub**:
- âŒ Creating issues/PRs on `automazeio/ccpm` template repository
- âŒ Closing issues without completion confirmation
- âŒ Deleting or hiding comments
- âŒ Modifying repository settings
- âŒ Using `--no-verify` or skipping hooks

**CCPM**:
- âŒ Using placeholder dates like `[Current date]` in frontmatter
- âŒ Using absolute paths with usernames in documentation
- âŒ Skipping daily log creation
- âŒ Leaving GitHub issues out of sync
- âŒ Modifying `created` timestamp after initial creation

### ğŸ“‹ Sprint Execution Checklist

**Daily (Every Day)**:
- [ ] Create daily log with actual progress
- [ ] Update GitHub issues (if worked on them)
- [ ] Update execution-status.md (if milestone reached)
- [ ] Commit CCPM changes
- [ ] Run tests before pushing
- [ ] Use real datetimes in all updates

**Weekly (End of Each Week)**:
- [ ] Create weekly review document
- [ ] Verify all 7 daily logs complete
- [ ] Sync all GitHub issues to current status
- [ ] Update PRD with progress
- [ ] Plan next week's work

**Sprint End (Every 2 Weeks)**:
- [ ] Create sprint retrospective
- [ ] Close all completed GitHub issues
- [ ] Update all epic execution-status files
- [ ] Update master PRD
- [ ] Create sprint summary document
- [ ] Archive sprint artifacts
- [ ] Plan next sprint

### ğŸ¯ Quality Standards

**Code Quality** (Enforced):
- Type hints on all functions (mypy strict mode)
- Docstrings on all public functions (Google style)
- Unit tests for all new code (90%+ coverage)
- Pass all linting (ruff)
- Pass all formatting (black, isort)
- No unused imports or variables

**CCPM Quality** (Enforced):
- Daily logs must contain real data, not estimates
- All timestamps must be from system (not hardcoded)
- All paths must be relative (not absolute)
- GitHub must be 100% synced at week end
- All frontmatter must be valid YAML
- All rules in `.claude/rules/` must be followed

### ğŸ“š Reference Documentation

**Must Read Before Starting**:
- `.claude/rules/worktree-operations.md` - Git worktree workflow
- `.claude/rules/github-operations.md` - GitHub integration rules
- `.claude/rules/frontmatter-operations.md` - Metadata standards
- `.claude/rules/datetime.md` - Timestamp requirements
- `.claude/rules/path-standards.md` - Path formatting rules
- `.claude/rules/standard-patterns.md` - Common patterns
- `.claude/SPRINT_CCPM_INTEGRATION.md` - CCPM maintenance guide

**Sprint Planning**:
- `.claude/SPRINT_PLAN_2026_Q1.md` - Detailed 4-week plan
- `.claude/SPRINT_SUMMARY.md` - Quick reference
- `.claude/SPRINT_VISUAL_ROADMAP.md` - Visual timeline

**Always Follow**:
1. Check rules before performing operations
2. Use templates for consistency
3. Update CCPM daily, not weekly
4. Sync GitHub continuously
5. Commit often with clear messages
6. Test before pushing
7. Document as you code

---

## Quick Start

```bash
# Install dependencies
cd file_organizer_v2
pip install -e .

# Install Ollama and pull models
ollama pull qwen2.5:3b-instruct-q4_K_M
ollama pull qwen2.5vl:7b-q4_K_M

# Run demo
python3 demo.py --sample --dry-run

# Run CLI
file-organizer --help
fo --help  # Short alias
```

---

## Project Structure

```
Local-File-Organizer/
â”œâ”€â”€ .claude/                          # CCPM project management
â”‚   â”œâ”€â”€ commands/                  # PM commands
â”‚   â”œâ”€â”€ prds/                      # Product requirements
â”‚   â”œâ”€â”€ epics/                     # Epic planning workspace
â”‚   â”œâ”€â”€ context/                   # Project-wide context
â”‚   â”œâ”€â”€ agents/                    # Specialized agent definitions
â”‚   â””â”€â”€ rules/                     # Standard operation rules
â”‚
â”œâ”€â”€ file_organizer_v2/                # Main application (~25K LOC)
â”‚   â”œâ”€â”€ src/file_organizer/
â”‚   â”‚   â”œâ”€â”€ models/                # AI model abstractions (650 LOC)
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py            # BaseModel interface, ModelConfig
â”‚   â”‚   â”‚   â”œâ”€â”€ text_model.py      # Ollama text generation
â”‚   â”‚   â”‚   â”œâ”€â”€ vision_model.py    # Vision-language models
â”‚   â”‚   â”‚   â””â”€â”€ audio_model.py     # Audio transcription (Phase 3)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/              # Business logic layer
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics/         # Storage & metrics analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ auto_tagging/      # Tag recommendation & learning
â”‚   â”‚   â”‚   â”œâ”€â”€ deduplication/     # Image & document deduplication
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ image_dedup/   # Perceptual hashing
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ document_dedup/# Embedding-based dedup
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ backup_manager.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ quality_assessor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ intelligence/      # User preference learning (21 modules)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ preference_tracker.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ profile_manager.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pattern_learner.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ confidence_engine.py
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ [16 more modules]
â”‚   â”‚   â”‚   â”œâ”€â”€ text_processor.py  # Text file pipeline (13 KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ vision_processor.py# Image/video pipeline (14 KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ pattern_analyzer.py# Pattern detection (16 KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ smart_suggestions.py# Placement suggestions (19 KB)
â”‚   â”‚   â”‚   â””â”€â”€ misplacement_detector.py# Context analysis (17 KB)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/                  # Main orchestrator
â”‚   â”‚   â”‚   â””â”€â”€ file_organizer.py  # FileOrganizer class
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ cli/                   # Command-line interfaces (6 modules)
â”‚   â”‚   â”‚   â”œâ”€â”€ dedupe.py          # Deduplication commands
â”‚   â”‚   â”‚   â”œâ”€â”€ profile.py         # Profile management
â”‚   â”‚   â”‚   â”œâ”€â”€ undo_redo.py       # Undo/redo commands
â”‚   â”‚   â”‚   â”œâ”€â”€ autotag.py         # Auto-tagging commands
â”‚   â”‚   â”‚   â””â”€â”€ analytics.py       # Analytics commands
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ history/               # Operation history (6 modules, ~50 KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ operation_history.py
â”‚   â”‚   â”‚   â”œâ”€â”€ operation_transaction.py
â”‚   â”‚   â”‚   â”œâ”€â”€ history_cleanup.py
â”‚   â”‚   â”‚   â”œâ”€â”€ history_exporter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ database_manager.py
â”‚   â”‚   â”‚   â””â”€â”€ models.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ undo/                  # Undo/redo system (5 modules, ~50 KB)
â”‚   â”‚   â”‚   â”œâ”€â”€ undo_manager.py
â”‚   â”‚   â”‚   â”œâ”€â”€ rollback_executor.py
â”‚   â”‚   â”‚   â”œâ”€â”€ operation_validator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ history_viewer.py
â”‚   â”‚   â”‚   â””â”€â”€ conflict_detector.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/                 # Utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ file_readers.py    # 10+ file format readers
â”‚   â”‚   â”‚   â”œâ”€â”€ text_processing.py # Text utilities
â”‚   â”‚   â”‚   â””â”€â”€ chart_generator.py # Visual analytics
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ config/                # Configuration management
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                     # 34 test files
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics/         # 4 test files
â”‚   â”‚   â”‚   â”œâ”€â”€ auto_tagging/      # 4 test files
â”‚   â”‚   â”‚   â”œâ”€â”€ intelligence/      # 8 test files
â”‚   â”‚   â”‚   â””â”€â”€ deduplication/
â”‚   â”‚   â”œâ”€â”€ history/               # 5 test files
â”‚   â”‚   â””â”€â”€ undo/                  # 4 test files
â”‚   â”‚
â”‚   â”œâ”€â”€ demo.py                    # CLI demo (~400 LOC)
â”‚   â””â”€â”€ pyproject.toml             # Project configuration
â”‚
â””â”€â”€ BUSINESS_REQUIREMENTS_DOCUMENT.md
```

---

## Architecture Overview

### Design Principles

1. **Privacy-First**: 100% local processing, zero cloud dependencies
2. **Model Abstraction**: Abstract AI model interface for framework flexibility
3. **Service Layer Pattern**: Business logic separate from models
4. **Strategy Pattern**: Different processors for different file types
5. **Type Safety**: Full type hints with strict mypy configuration
6. **Resource Management**: Context managers for automatic cleanup

### Core Components

| Component | Purpose | Location | Status |
|-----------|---------|----------|--------|
| **BaseModel** | Abstract AI model interface | `models/base.py` | âœ… Core |
| **ModelConfig** | Unified model configuration | `models/base.py` | âœ… Core |
| **TextModel** | Ollama text generation | `models/text_model.py` | âœ… Active |
| **VisionModel** | Vision-language wrapper | `models/vision_model.py` | âœ… Active |
| **AudioModel** | Audio transcription | `models/audio_model.py` | ğŸ“… Phase 3 |
| **TextProcessor** | Text file pipeline | `services/text_processor.py` | âœ… Active |
| **VisionProcessor** | Image/video pipeline | `services/vision_processor.py` | âœ… Active |
| **FileOrganizer** | Main orchestrator | `core/file_organizer.py` | âœ… Active |
| **PatternAnalyzer** | Naming pattern detection | `services/pattern_analyzer.py` | âœ… Active |
| **SmartSuggestions** | Placement suggestions | `services/smart_suggestions.py` | âœ… Active |
| **Intelligence** | User preference learning | `services/intelligence/` | âœ… Active |
| **Deduplication** | Duplicate detection | `services/deduplication/` | âœ… Active |
| **OperationHistory** | Operation tracking | `history/` | âœ… Active |
| **UndoManager** | Undo/redo system | `undo/` | âœ… Active |

### Data Flow

```
Input File â†’ FileOrganizer â†’ File Type Detection
    â†“
Text Files: TextProcessor â†’ TextModel (Qwen 2.5 3B)
    â†“
    â””â†’ Generate description, folder name, filename

Image/Video: VisionProcessor â†’ VisionModel (Qwen 2.5-VL 7B)
    â†“
    â””â†’ Visual analysis, OCR, description

Audio: AudioModel â†’ faster-whisper (Phase 3)
    â†“
    â””â†’ Transcription, metadata extraction

All Processors â†’ PatternAnalyzer â†’ SmartSuggestions
    â†“
    â””â†’ Intelligence Services â†’ User Preference Learning

Final Output: Organized files + Operation history
```

### Key Data Classes

```python
@dataclass
class ModelConfig:
    """AI model configuration"""
    name: str                      # Model identifier
    model_type: ModelType          # TEXT, VISION, AUDIO, VIDEO
    quantization: str = "q4_k_m"   # Quantization level
    device: DeviceType = AUTO      # CPU, CUDA, MPS, METAL
    temperature: float = 0.5       # Generation temperature
    max_tokens: int = 3000         # Context limit
    framework: str = "ollama"      # Inference framework

@dataclass
class ProcessedFile:
    """Text processing result"""
    filename: str
    description: str
    folder_name: str
    new_filename: str
    confidence: float

@dataclass
class ProcessedImage:
    """Vision processing result"""
    filename: str
    description: str
    folder_name: str
    new_filename: str
    ocr_text: Optional[str]
    confidence: float
```

---

## Dependencies & Setup

### System Requirements

- **Python**: 3.12+ (strict type checking)
- **Ollama**: Latest version for local inference
- **Storage**: ~10 GB for models
- **RAM**: 8 GB minimum, 16 GB recommended

### Installation

```bash
# 1. Clone repository
git clone <repo-url>
cd Local-File-Organizer/file_organizer_v2

# 2. Install Ollama (if not installed)
# macOS/Linux: curl -fsSL https://ollama.ai/install.sh | sh
# Windows: Download from ollama.ai

# 3. Pull required models
ollama pull qwen2.5:3b-instruct-q4_K_M    # Text: ~1.9 GB
ollama pull qwen2.5vl:7b-q4_K_M           # Vision: ~6.0 GB

# 4. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 5. Install package
pip install -e .

# 6. Verify installation
file-organizer --version
fo --version
```

### Core Dependencies

**AI Inference**:
- `ollama>=0.1.0` - Local LLM execution

**File Processing**:
- `Pillow>=10.0.0` - Images
- `PyMuPDF>=1.23.0` - PDFs
- `python-docx>=1.0.0` - Word docs
- `pandas>=2.0.0` - Spreadsheets
- `openpyxl>=3.1.0` - Excel
- `python-pptx>=0.6.0` - PowerPoint
- `ebooklib>=0.18` - EPUB

**NLP & Text**:
- `nltk>=3.8.0` - Text processing
- `faster-whisper>=0.10.0` - Audio (Phase 3)

**CLI & UI**:
- `typer[all]>=0.12.0` - CLI framework
- `rich>=13.0.0` - Rich output
- `textual>=0.48.0` - TUI (Phase 2)

**Database**:
- `sqlalchemy>=2.0.0` - ORM
- `alembic>=1.13.0` - Migrations

**Async & Queue**:
- `celery>=5.3.0` - Task queue
- `redis>=5.0.0` - Broker
- `websockets>=12.0` - WebSockets
- `httpx>=0.26.0` - Async HTTP

**Deduplication**:
- `imagededup>=0.3.0` - Image similarity

### Development Dependencies

```bash
# Install with dev dependencies
pip install -e ".[dev]"

# Required for development
- pytest>=7.4.0              # Testing
- pytest-asyncio             # Async tests
- pytest-cov                 # Coverage
- pytest-mock                # Mocking
- mypy>=1.8.0                # Type checking
- ruff>=0.1.0                # Linting
- black>=23.12.0             # Formatting
- isort>=5.13.0              # Import sorting
```

---

## AI Model Configuration

### Supported Models

**Text Models** (via Ollama):
- `qwen2.5:3b-instruct-q4_K_M` - Default text model (~1.9 GB)
- 4-bit quantization for speed/memory balance
- Context window: 4,096 tokens

**Vision Models** (via Ollama):
- `qwen2.5vl:7b-q4_K_M` - Default vision model (~6.0 GB)
- Multi-modal: images + text input
- OCR + visual understanding

**Audio Models** (Phase 3):
- `faster-whisper` - Local transcription
- Supports multiple languages

### Device Support

```python
from file_organizer.models.base import DeviceType

DeviceType.AUTO    # Automatic detection (recommended)
DeviceType.CPU     # CPU inference (universal)
DeviceType.CUDA    # NVIDIA GPU (fastest)
DeviceType.MPS     # Apple Silicon (fast)
DeviceType.METAL   # Apple Metal (fast)
```

### Model Instantiation

```python
from file_organizer.models import TextModel, VisionModel, ModelConfig

# Text model with custom config
text_config = ModelConfig(
    name="qwen2.5:3b-instruct-q4_K_M",
    model_type=ModelType.TEXT,
    temperature=0.5,
    max_tokens=3000,
    device=DeviceType.AUTO
)
text_model = TextModel(text_config)

# Vision model with defaults
vision_model = VisionModel()

# Use as context manager (recommended)
with TextModel() as model:
    result = model.generate("Describe this file...")
```

### Adding New Models

To add a new model provider:

1. Create new class extending `BaseModel` in `models/`
2. Implement required methods: `generate()`, `generate_stream()`, `cleanup()`
3. Update `ModelConfig.framework` enum
4. Add tests in `tests/models/`

---

## Development Guidelines

### Code Style

**Formatting** (enforced):
- Black for code formatting
- isort for import sorting
- Line length: 88 characters (Black default)

**Linting** (enforced):
- Ruff with strict rules
- No unused imports/variables
- Consistent naming conventions

**Type Checking** (enforced):
```ini
[tool.mypy]
strict = true
disallow_untyped_defs = true
disallow_any_untyped = true
warn_return_any = true
warn_unused_ignores = true
```

### Naming Conventions

**Files & Modules**:
- `snake_case.py` for all Python files
- Match class name: `TextProcessor` â†’ `text_processor.py`

**Classes**:
- `PascalCase` for classes
- `BaseModel`, `TextProcessor`, `FileOrganizer`

**Functions & Variables**:
- `snake_case` for functions and variables
- `process_file()`, `file_path`, `model_config`

**Constants**:
- `UPPER_SNAKE_CASE` for constants
- `MAX_TOKENS`, `DEFAULT_TEMPERATURE`

**Private**:
- Single underscore prefix: `_internal_helper()`
- Double underscore for name mangling: `__private_attr`

### File Organization

**Module Structure**:
```python
"""Module docstring.

Detailed description of module purpose.
"""

# Standard library imports
import os
from pathlib import Path
from typing import Optional, List

# Third-party imports
import ollama
from rich.console import Console

# Local imports
from file_organizer.models.base import BaseModel
from file_organizer.utils import sanitize_filename

# Constants
DEFAULT_TEMPERATURE = 0.5

# Classes and functions
class MyClass:
    """Class docstring."""
    pass
```

### Error Handling

**Custom Exceptions**:
```python
# Define in relevant module
class FileReadError(Exception):
    """Raised when file cannot be read."""
    pass

# Use with context
try:
    content = read_file(path)
except FileNotFoundError:
    raise FileReadError(f"File not found: {path}")
```

**Logging**:
```python
import logging

logger = logging.getLogger(__name__)

# Use appropriate levels
logger.debug("Processing file: %s", filename)
logger.info("File organized successfully")
logger.warning("Model took longer than expected")
logger.error("Failed to process file: %s", error)
```

### Documentation

**Docstrings** (Google style):
```python
def process_file(file_path: Path, model: TextModel) -> ProcessedFile:
    """Process a text file using AI model.

    Args:
        file_path: Path to the file to process
        model: AI model instance to use

    Returns:
        ProcessedFile containing organization metadata

    Raises:
        FileReadError: If file cannot be read
        ModelError: If AI model fails

    Example:
        >>> result = process_file(Path("doc.txt"), text_model)
        >>> print(result.folder_name)
        'Documents/Technical'
    """
    pass
```

### Type Hints

**Always use type hints**:
```python
# Good
def organize_files(
    input_dir: Path,
    output_dir: Path,
    model: BaseModel
) -> List[ProcessedFile]:
    pass

# Bad
def organize_files(input_dir, output_dir, model):
    pass
```

**Use modern syntax** (Python 3.12+):
```python
# Good (3.12+)
def process(items: list[str]) -> dict[str, int]:
    pass

# Avoid (legacy)
from typing import List, Dict
def process(items: List[str]) -> Dict[str, int]:
    pass
```

### Git Commit Messages

**Format**:
```
<type>(<scope>): <subject>

<body>

<footer>
```

**Types**:
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation
- `style`: Formatting
- `refactor`: Code restructuring
- `test`: Tests
- `chore`: Maintenance

**Examples**:
```
feat(models): Add support for GPT-4V vision model

Implement GPT4VisionModel class extending BaseModel.
Includes streaming support and context management.

Closes #42

fix(text_processor): Handle empty PDF files gracefully

Previously crashed on empty PDFs. Now returns empty
string with warning log.

Fixes #56
```

---

## Testing Strategy

### Test Organization

```
tests/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ analytics/           # Analytics tests
â”‚   â”œâ”€â”€ auto_tagging/        # Auto-tagging tests
â”‚   â”œâ”€â”€ intelligence/        # Intelligence service tests (8 files)
â”‚   â””â”€â”€ deduplication/       # Deduplication tests
â”œâ”€â”€ history/                 # History system tests (5 files)
â”œâ”€â”€ undo/                    # Undo/redo tests (4 files)
â””â”€â”€ test_smart_suggestions.py
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=file_organizer --cov-report=html

# Run specific test file
pytest tests/services/test_text_processor.py

# Run specific test
pytest tests/services/test_text_processor.py::test_process_pdf

# Run marked tests
pytest -m unit          # Unit tests only
pytest -m integration   # Integration tests only
pytest -m "not slow"    # Exclude slow tests

# Verbose output
pytest -v

# Stop on first failure
pytest -x
```

### Test Markers

```python
import pytest

@pytest.mark.unit
def test_sanitize_filename():
    """Unit test for filename sanitization."""
    pass

@pytest.mark.integration
def test_file_organization_pipeline():
    """Integration test for full pipeline."""
    pass

@pytest.mark.slow
def test_large_batch_processing():
    """Slow test for batch processing."""
    pass
```

### Writing Tests

**Structure**:
```python
import pytest
from pathlib import Path
from file_organizer.services import TextProcessor

@pytest.fixture
def text_processor():
    """Create TextProcessor instance."""
    return TextProcessor()

@pytest.fixture
def sample_file(tmp_path):
    """Create sample text file."""
    file_path = tmp_path / "sample.txt"
    file_path.write_text("Sample content")
    return file_path

def test_process_text_file(text_processor, sample_file):
    """Test processing a text file."""
    # Arrange
    expected_folder = "Documents"

    # Act
    result = text_processor.process(sample_file)

    # Assert
    assert result.folder_name == expected_folder
    assert result.confidence > 0.5
```

**Mocking AI Models**:
```python
from unittest.mock import Mock, patch

def test_process_with_mock_model(text_processor):
    """Test processing with mocked AI model."""
    # Create mock
    mock_model = Mock()
    mock_model.generate.return_value = "Mocked description"

    # Use mock
    with patch('file_organizer.models.text_model.TextModel', return_value=mock_model):
        result = text_processor.process(Path("test.txt"))

    # Verify
    assert result.description == "Mocked description"
    mock_model.generate.assert_called_once()
```

### Coverage Goals

- **Unit tests**: 80%+ coverage
- **Integration tests**: Key workflows
- **E2E tests**: demo.py scenarios

### CI/CD Integration

```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      - run: pip install -e ".[dev]"
      - run: pytest --cov --cov-report=xml
      - uses: codecov/codecov-action@v3
```

---

## Common Workflows

### 1. Adding a New File Type

```bash
# 1. Add format reader in utils/file_readers.py
def read_new_format_file(file_path: Path) -> str:
    """Read .newformat files."""
    # Implementation
    pass

# 2. Update text_processor.py or vision_processor.py
SUPPORTED_FORMATS = {
    '.newformat': read_new_format_file,
    # ... existing formats
}

# 3. Add tests
# tests/test_new_format.py

# 4. Update documentation
# Add to Supported File Types section
```

### 2. Adding a New AI Model Provider

```python
# 1. Create new model class
# file_organizer/models/new_provider_model.py

from file_organizer.models.base import BaseModel, ModelConfig
from typing import Iterator

class NewProviderModel(BaseModel):
    """Model implementation for NewProvider."""

    def __init__(self, config: ModelConfig):
        super().__init__(config)
        # Initialize provider client

    def generate(self, prompt: str) -> str:
        """Generate text response."""
        # Implementation
        pass

    def generate_stream(self, prompt: str) -> Iterator[str]:
        """Stream text response."""
        # Implementation
        pass

    def cleanup(self) -> None:
        """Cleanup resources."""
        # Implementation
        pass

# 2. Add tests
# tests/models/test_new_provider_model.py

# 3. Update ModelConfig.framework enum
# models/base.py
```

### 3. Adding a New Service

```python
# 1. Create service module
# file_organizer/services/my_service.py

from pathlib import Path
from dataclasses import dataclass

@dataclass
class MyServiceResult:
    """Result from my service."""
    field1: str
    field2: int

class MyService:
    """Service for doing X."""

    def __init__(self):
        # Initialize service
        pass

    def process(self, file_path: Path) -> MyServiceResult:
        """Process file."""
        # Implementation
        pass

# 2. Add tests
# tests/services/test_my_service.py

# 3. Integrate with FileOrganizer
# core/file_organizer.py

# 4. Add CLI command if needed
# cli/my_service.py
```

### 4. Creating a New CLI Command

```python
# 1. Create command module
# file_organizer/cli/my_command.py

import typer
from rich.console import Console

app = typer.Typer()
console = Console()

@app.command()
def my_command(
    input_path: Path = typer.Argument(..., help="Input path"),
    option: bool = typer.Option(False, "--option", help="Enable option")
):
    """My command description."""
    console.print("[bold]Running my command...[/bold]")
    # Implementation

# 2. Register in main CLI
# file_organizer/cli/__init__.py
from file_organizer.cli.my_command import app as my_command_app
app.add_typer(my_command_app, name="my-command")

# 3. Test it
file-organizer my-command --help
```

### 5. Debugging Model Issues

```python
# Enable debug logging
import logging
logging.basicConfig(level=logging.DEBUG)

# Test model directly
from file_organizer.models import TextModel

with TextModel() as model:
    response = model.generate("Test prompt")
    print(f"Response: {response}")

# Check Ollama status
ollama list  # List available models
ollama ps    # Show running models

# Run model manually
ollama run qwen2.5:3b-instruct-q4_K_M "Test prompt"
```

### 6. Running Demo with Custom Files

```python
# Organize specific directory
python3 demo.py --input ~/Downloads --output ~/Organized

# Dry run (preview only)
python3 demo.py --input ~/Downloads --output ~/Organized --dry-run

# With sample files
python3 demo.py --sample

# Verbose output
python3 demo.py --input ~/Downloads --output ~/Organized --verbose
```

### 7. Database Migrations

```bash
# Create new migration
cd file_organizer_v2
alembic revision -m "Add new table"

# Edit migration file
# file_organizer/alembic/versions/xxx_add_new_table.py

# Apply migration
alembic upgrade head

# Rollback migration
alembic downgrade -1

# Check current version
alembic current
```

---

## Supported File Types

### Document Formats (9 types)

| Format | Extension | Reader Function | Status |
|--------|-----------|----------------|--------|
| Plain Text | `.txt` | `read_text_file()` | âœ… |
| Markdown | `.md` | `read_markdown_file()` | âœ… |
| PDF | `.pdf` | `read_pdf_file()` | âœ… |
| Word | `.docx`, `.doc` | `read_docx_file()` | âœ… |
| Spreadsheet | `.csv`, `.xlsx`, `.xls` | `read_excel_file()` | âœ… |
| Presentation | `.ppt`, `.pptx` | `read_presentation_file()` | âœ… |
| E-book | `.epub` | `read_epub_file()` | âœ… |

### Image Formats (6 types)

| Format | Extension | Processor | Status |
|--------|-----------|-----------|--------|
| JPEG | `.jpg`, `.jpeg` | VisionProcessor | âœ… |
| PNG | `.png` | VisionProcessor | âœ… |
| GIF | `.gif` | VisionProcessor | âœ… |
| BMP | `.bmp` | VisionProcessor | âœ… |
| TIFF | `.tiff`, `.tif` | VisionProcessor | âœ… |

### Video Formats (5 types)

| Format | Extension | Processor | Status |
|--------|-----------|-----------|--------|
| MP4 | `.mp4` | VisionProcessor | âœ… |
| AVI | `.avi` | VisionProcessor | âœ… |
| MKV | `.mkv` | VisionProcessor | âœ… |
| MOV | `.mov` | VisionProcessor | âœ… |
| WMV | `.wmv` | VisionProcessor | âœ… |

### Audio Formats (5 types) - Phase 3

| Format | Extension | Processor | Status |
|--------|-----------|-----------|--------|
| MP3 | `.mp3` | AudioModel | ğŸ“… Phase 3 |
| WAV | `.wav` | AudioModel | ğŸ“… Phase 3 |
| FLAC | `.flac` | AudioModel | ğŸ“… Phase 3 |
| M4A | `.m4a` | AudioModel | ğŸ“… Phase 3 |
| OGG | `.ogg` | AudioModel | ğŸ“… Phase 3 |

**Total**: 25 file types supported (20 active, 5 planned)

---

## Performance Notes

### Processing Speed

| File Type | Average Time | Model Used | Notes |
|-----------|-------------|------------|-------|
| Text (< 1 MB) | 2-5 seconds | Qwen 2.5 3B | Fast, local |
| Text (1-10 MB) | 5-15 seconds | Qwen 2.5 3B | Chunking applied |
| Image | 3-8 seconds | Qwen 2.5-VL 7B | GPU accelerated |
| Video | 5-20 seconds | Qwen 2.5-VL 7B | Samples frames |
| PDF (text) | 3-10 seconds | Qwen 2.5 3B | Depends on pages |
| PDF (scanned) | 8-20 seconds | Qwen 2.5-VL 7B | OCR required |

### Optimization Tips

1. **Use GPU acceleration** if available (CUDA/MPS/Metal)
2. **Batch processing** for multiple files
3. **Adjust temperature** (lower = faster, more deterministic)
4. **Reduce max_tokens** if descriptions are too long
5. **Use quantized models** (Q4 is good balance)
6. **Close unused models** to free memory

### Memory Usage

| Component | RAM Usage | Notes |
|-----------|-----------|-------|
| Qwen 2.5 3B (Q4) | ~2.5 GB | Text model |
| Qwen 2.5-VL 7B (Q4) | ~5.5 GB | Vision model |
| Base application | ~200 MB | Python + deps |
| Per file buffer | ~50-100 MB | During processing |

**Recommended**: 8 GB RAM minimum, 16 GB for comfortable performance

### Scalability

- **Single file**: Synchronous processing
- **Batch files**: Parallel processing planned (Phase 5)
- **Large datasets**: Use Celery task queue (Phase 5)
- **Enterprise**: Microservices architecture (Phase 6)

---

## Additional Resources

### Documentation

- **Business Requirements**: `BUSINESS_REQUIREMENTS_DOCUMENT.md`
- **API Docs**: Generated from docstrings
- **CLI Help**: `file-organizer --help`

### Phase Roadmap

- âœ… **Phase 1**: Text + Image processing (Complete)
- ğŸš§ **Phase 2**: Modern UI (TUI with Textual)
- ğŸ“… **Phase 3**: Audio support + advanced video
- ğŸ“… **Phase 4**: Deduplication + user learning
- ğŸ“… **Phase 5**: Event-driven microservices
- ğŸ“… **Phase 6**: Enterprise features

### Contributing

1. Fork repository
2. Create feature branch: `git checkout -b feature/my-feature`
3. Make changes with tests
4. Run quality checks: `pytest && mypy . && ruff check .`
5. Commit: `git commit -m "feat: add my feature"`
6. Push and create PR

### Support

- Issues: GitHub Issues
- Questions: GitHub Discussions
- Email: [Add contact email]

---

**Last Updated**: 2026-01-23
**Version**: 2.0.0
**Maintainers**: [Add maintainer names]